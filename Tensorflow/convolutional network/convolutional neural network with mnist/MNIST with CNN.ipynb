{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            **Order of execution**\n",
    "\n",
    "**get image in image form**\n",
    "\n",
    "                            **{layers}**\n",
    "\n",
    "**convolve image**\n",
    "\n",
    "**apply relu to it**\n",
    "\n",
    "**pool it**\n",
    "\n",
    "\n",
    "**flatten image**\n",
    "\n",
    "**make it fc**\n",
    "\n",
    "**apply relu**\n",
    "\n",
    "**apply dropout**\n",
    "\n",
    "**get y_model**\n",
    "\n",
    "**apply softmax with cross entropy for loss calculation**\n",
    "\n",
    "**optimizer**\n",
    "\n",
    "**run session**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_Data_Set\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_Data_Set\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_Data_Set\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_Data_Set\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_Data_Set', one_hot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {HELPER FUNCTIONS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "    # weight\n",
    "    # bias\n",
    "def init_weight(shape_of_filter):\n",
    "    weight = tf.truncated_normal(shape = shape_of_filter, stddev=0.1)\n",
    "    return tf.Variable(weight)\n",
    "\n",
    "def init_bias():\n",
    "    bias = tf.constant(0.1, shape = [1])\n",
    "    return tf.Variable(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolutional layer + relu\n",
    "#getting 2 dimension from 4 dimension image\n",
    "#strides = [1,1,1,1] move 1 in all direction\n",
    "\n",
    "\n",
    "def convo2d(image, weight):\n",
    "    return tf.nn.conv2d(input = image, filter = weight, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "\n",
    "\n",
    "# this shape is shape of filter i.e [image_height, image_width, input_channel, channel_out]\n",
    "\n",
    "def convolutional_layer(image, shape):\n",
    "    weight = init_weight(shape)\n",
    "    # this each bias for each channels\n",
    "    bias = init_bias()\n",
    "    # applying relu to convolved image to get non linearity\n",
    "    return tf.nn.relu(convo2d(image, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling\n",
    "# we are doing max pool \n",
    "# [1,2,2,1], first 1 is for number of image and last 1 is for input_channel , 2 X 2 is for window size\n",
    "# of filter \n",
    "def pooled_layer(convolved_image):\n",
    "    return tf.nn.max_pool(convolved_image, ksize = [1,2,2,1], strides = [1, 2, 2, 1], padding = 'SAME') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten fully-connected\n",
    "\n",
    "# flatten \n",
    "def flatten_layers(pooled_image):\n",
    "    '''\n",
    "    pooled_image : last pooled layer to be flattened\n",
    "    '''\n",
    "    pooled_image_shape = pooled_image.get_shape()\n",
    "    flattened_feature = pooled_image_shape[1:4].num_elements()\n",
    "    flattened_image = tf.reshape(pooled_image,[-1, flattened_feature])\n",
    "    return flattened_image\n",
    "\n",
    "# matmul\n",
    "# apply relu\n",
    "\n",
    "def fully_connected(flattened_image, size):\n",
    "    '''\n",
    "    flattened_image : the flattened image (rows for weight)\n",
    "    size : number of neurons to be connected (columns for weight)\n",
    "    '''\n",
    "    flattened_image_shape = flattened_image.get_shape()\n",
    "    weight = init_weight([int(flattened_image_shape[1]), size])\n",
    "    # each bias for each output\n",
    "    bias = init_bias()\n",
    "    return (tf.matmul(flattened_image, weight)+ bias)\n",
    "\n",
    "# apply dropout\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "def dropout(fully_connected_image_applied_relu, keep_prob):\n",
    "    '''\n",
    "    fully_connected_image_with_applied_relu : self explanatory\n",
    "    '''\n",
    "    drop_out_layer = tf.nn.dropout((fully_connected_image_applied_relu), keep_prob = keep_prob)\n",
    "    return drop_out_layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder\n",
    "xph = tf.placeholder(tf.float32, [None, 784])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#layers\n",
    "image = tf.reshape(xph, [-1, 28, 28, 1])\n",
    "\n",
    "convolutional_layer_1 = convolutional_layer(image, shape = [2,2,1,32])\n",
    "pooled_layer_1 = pooled_layer(convolutional_layer_1)\n",
    "\n",
    "convolutional_layer_2 = convolutional_layer(convolutional_layer_1, [2,2,32,64])\n",
    "pooled_layer_2 = pooled_layer(convolutional_layer_2)\n",
    "\n",
    "#fully connected with applied relu\n",
    "flattened_layer = flatten_layers(pooled_layer_2)\n",
    "fully_connted = tf.nn.relu(fully_connected(flattened_layer, 500))\n",
    "\n",
    "drop_out_layer = dropout(fully_connted, keep_prob)\n",
    "\n",
    "# y_model\n",
    "\n",
    "y_model = fully_connected(drop_out_layer, 10)\n",
    "\n",
    "#apply softmax to it to calculate loss\n",
    "\n",
    "cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_model))\n",
    "\n",
    "# optimize the loss\n",
    "\n",
    "optimizer  = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "train = optimizer.minimize(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    epoch = 1000\n",
    "    for steps in range((epoch+1)):\n",
    "        batch_x, batch_y = mnist.train.next_batch(100)\n",
    "        sess.run(train, feed_dict = {xph:batch_x, y_true:batch_y,keep_prob:0.5})\n",
    "    \n",
    "    \n",
    "        if steps%100 == 0:\n",
    "            #these matches are true and false so we have to cast it to 0 and 1 and finding the average\n",
    "            matches = tf.equal(tf.argmax(y_true,1), tf.argmax(y_model,1))\n",
    "            percent = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "            acc = sess.run(percent, feed_dict = {xph:mnist.test.images, y_true:mnist.test.labels,keep_prob:1.0})\n",
    "            print('At epoch {}\\nAccuracy is {}\\n\\n'.format(steps, acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
